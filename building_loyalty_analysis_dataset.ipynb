{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First step is import data from Parse.ly's AWS bucket for the relevant  time period into Google BigQuery.  \n",
    "The key and passphrase for these are with rachit.kinger@jpimedia.co.uk. More key and passwords can be obtained by reaching out directly to Parse.ly.  \n",
    "This data is best imported via GCP's GUI. Go to `GCP > Storage > Transfer` and the steps from there should be obvious.  \n",
    "Remember to specify file filters to download data only for the relevant months.  \n",
    "\n",
    "Once this data has been download the follow these steps to import into a single 'large' database. DO NOT use this database for analysis. Only around 30% of this dataset is useful for us. This database will have a column called `action` which has mostly two values, `pageview` or `heartbeat`. The `pageview` is what is of interest to us and it occupies only 30% of the database.  \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# the following commands were run from bash using gsutil\n",
    "# create empty table with the rawdata schema\n",
    "%%bash\n",
    "bq mk -t --schema /home/rachit/gdrive/GCP/bigquery_parsely/bqtable_from_cli/parsely_rawdata_schema.json \\\n",
    "--time_partitioning_type=DAY --time_partitioning_field ts_action \\\n",
    "--require_partition_filter=TRUE --clustering_fields='apikey,action' \\\n",
    "parsely.rawdata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# the following commands were run from bash using gsutil\n",
    "# use the following command to load the raw parsely data into the the empty table created in previous step\n",
    "%%bash\n",
    "bq load --source_format=NEWLINE_DELIMITED_JSON --max_bad_records=1000 --ignore_unknown_values parsely.rawdata gs://parsely/*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Please visit this URL to authorize this application: https://accounts.google.com/o/oauth2/auth?response_type=code&client_id=306244342965-pv1n0vhib5nv2ks66pnj59csdf8cqor0.apps.googleusercontent.com&redirect_uri=urn%3Aietf%3Awg%3Aoauth%3A2.0%3Aoob&scope=https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fbigquery&state=m36ZbrRtyeg4cEzKUUUf62TuDRcXTv&prompt=consent&access_type=offline\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Enter the authorization code:  4/_ADXejaFJx7AY1KqZySJOVYHxzPFulljKCFpx57b_NXE-2DN7RaHxNQ\n"
     ]
    }
   ],
   "source": [
    "# use oauth to authenticate access into GCP and bigquery\n",
    "# toggle this variable depending on whether you are on a machine that has an Internet browser or not\n",
    "launch_browser = False \n",
    "# The `launch_browser` boolean variable indicates if a local server is used\n",
    "# as the callback URL in the auth flow. A value of `True` is recommended,\n",
    "# but a local server does not work if accessing the application remotely,\n",
    "# such as over SSH or from a remote Jupyter notebook.\n",
    "\n",
    "# if you are not Rachit Kinger please build your own oauth access client id and key and set the \n",
    "# path in the function below to your own client ke\n",
    "from google_auth_oauthlib import flow\n",
    "\n",
    "appflow = flow.InstalledAppFlow.from_client_secrets_file(\n",
    "    '/home/rachit/gdrive/GCP/oauth_client_key/data-team-rachit-kinger-desktop-apps.json',\n",
    "    scopes = ['https://www.googleapis.com/auth/bigquery'])\n",
    "\n",
    "if launch_browser:\n",
    "    appflow.run_local_server()\n",
    "else:\n",
    "    appflow.run_console()\n",
    "    \n",
    "credentials = appflow.credentials"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# access bigquery\n",
    "from google.cloud import bigquery\n",
    "project_id = \"bigquery-test-165213\"\n",
    "client = bigquery.Client(project = project_id, credentials = credentials)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
